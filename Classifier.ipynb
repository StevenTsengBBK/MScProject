{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import librosa\n",
    "import librosa.display\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "dataset_info_csv = './UrbanSound8K.csv'\n",
    "dataset_info = read_csv(dataset_info_csv, header=0)\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "# Features\n",
    "CLASS_LABELS = [4,5]\n",
    "\n",
    "names = ['filename'\n",
    "          ,'fold','duration'\n",
    "          ,'chroma_stft_mean'\n",
    "          ,'chroma_stft_variance'\n",
    "          , 'rmse_mean'\n",
    "          , 'rmse_variance'\n",
    "          , 'spectral_centroid_mean'\n",
    "          , 'spectral_centroid_variance'\n",
    "          , 'spectral_bandwidth_mean'\n",
    "          , 'spectral_bandwidth_variance'\n",
    "          , 'spectral_rolloff_mean'\n",
    "          , 'spectral_rolloff_variance'\n",
    "          , 'zero_crossing_rate_mean'\n",
    "          , 'zero_crossing_rate_variance']\n",
    "for i in range (1,41):\n",
    "    names.append(\"MFCC_\"+str(i)+\"_mean\")\n",
    "    names.append(\"MFCC_\"+str(i)+\"_variance\")\n",
    "\n",
    "names.append('class_ID')\n",
    "print(names)\n",
    "\n",
    "# Read all WAV files and extract all features write into a new csv file\n",
    "\n",
    "with open('urbansound8k_features.csv', 'w', newline='') as allFeatures:\n",
    "    writer = csv.writer(allFeatures)\n",
    "    writer.writerow(names)\n",
    "\n",
    "    for file in dataset_info.values:\n",
    "        if int(file[7]) in CLASS_LABELS:\n",
    "            audio_file = \"urbansound8k/\" + \"fold\" + str(file[6]) + \"/\" + file[0]\n",
    "            series , sample_rate = librosa.load(audio_file)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=series, sr=sample_rate)\n",
    "            rmse = librosa.feature.rms(y=series)\n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=series, sr=sample_rate)\n",
    "            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=series, sr=sample_rate)\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(y=series, sr=sample_rate)\n",
    "            zero_crossing_rate = librosa.feature.zero_crossing_rate(series)\n",
    "            MFCC = librosa.feature.mfcc(y=series, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "            chroma_stft_mean = np.mean(chroma_stft)\n",
    "            chroma_stft_variance = np.var(chroma_stft)\n",
    "            rmse_mean = np.mean(rmse)\n",
    "            rmse_variance = np.var(rmse)\n",
    "            spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "            spectral_centroid_variance = np.var(spectral_centroid)\n",
    "            spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
    "            spectral_bandwidth_variance = np.var(spectral_bandwidth)\n",
    "            spectral_rolloff_mean = np.mean(spectral_rolloff)\n",
    "            spectral_rolloff_variance = np.var(spectral_rolloff)\n",
    "            zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
    "            zero_crossing_rate_variance = np.var(zero_crossing_rate)\n",
    "\n",
    "            sample = [file[0].replace(\".wav\",\"\")\n",
    "                      , file[6]\n",
    "                      , file[4]\n",
    "                      , chroma_stft_mean\n",
    "                      , chroma_stft_variance\n",
    "                      , rmse_mean\n",
    "                      , rmse_variance\n",
    "                      , spectral_centroid_mean\n",
    "                      , spectral_centroid_variance\n",
    "                      , spectral_bandwidth_mean\n",
    "                      , spectral_bandwidth_variance\n",
    "                      , spectral_rolloff_mean, spectral_rolloff_variance\n",
    "                      , zero_crossing_rate_mean\n",
    "                      , zero_crossing_rate_variance]\n",
    "\n",
    "            for mfcc in MFCC:\n",
    "                mfcc_mean = np.mean(mfcc)\n",
    "                mfcc_variance = np.mean(mfcc)\n",
    "                sample.append(mfcc_mean)\n",
    "                sample.append(mfcc_variance)\n",
    "\n",
    "            sample.append(file[7])\n",
    "\n",
    "            writer.writerow(sample)\n",
    "    allFeatures.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Read Feature PreProcessed before\n",
    "dataset_file = './urbansound8k_features.csv'\n",
    "dataset = read_csv(dataset_file)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "# Set up the dataset for crossvalidation\n",
    "train = []\n",
    "train_label = []\n",
    "holdout = []\n",
    "holdout_label = []\n",
    "\n",
    "for sample in dataset:\n",
    "    if sample[1] < 6:\n",
    "        train.append(sample[2:-1])\n",
    "        train_label.append(sample[-1])\n",
    "    elif sample[1] > 7:\n",
    "        holdout.append(sample[2:-1])\n",
    "        holdout_label.append(sample[-1])\n",
    "\n",
    "train = np.array(train)\n",
    "train_label = np.array(train_label)\n",
    "holdout = np.array(holdout)\n",
    "holdout_label = np.array(holdout_label)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "transformed_train = scaler.fit_transform(train)\n",
    "scaler = StandardScaler()\n",
    "transformed_holdout = scaler.fit_transform(holdout)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1,0.1,0.01,0.001,0.0001]},\n",
    "                   {'kernel':['linear'], 'C':[1,10,100,1000]}]\n",
    "\n",
    "scores = ['accuracy','f1_macro' ,'precision_macro', 'recall_macro', 'roc_auc']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring= score, cv = 5, n_jobs = 2\n",
    "    )\n",
    "    clf.fit(transformed_train, train_label)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = holdout_label, clf.predict(transformed_holdout)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# Read Feature PreProcessed before\n",
    "dataset_file = './urbansound8k_features.csv'\n",
    "dataset = read_csv(dataset_file)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "# Set up the dataset for crossvalidation\n",
    "train = []\n",
    "train_label = []\n",
    "holdout = []\n",
    "holdout_label = []\n",
    "\n",
    "for sample in dataset:\n",
    "    if sample[1] < 6:\n",
    "        train.append(sample[2:-1])\n",
    "        train_label.append(sample[-1])\n",
    "    elif sample[1] > 7:\n",
    "        holdout.append(sample[2:-1])\n",
    "        holdout_label.append(sample[-1])\n",
    "\n",
    "train = np.array(train)\n",
    "train_label = np.array(train_label)\n",
    "holdout = np.array(holdout)\n",
    "holdout_label = np.array(holdout_label)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "transformed_train = scaler.fit_transform(train)\n",
    "scaler = StandardScaler()\n",
    "transformed_holdout = scaler.fit_transform(holdout)\n",
    "\n",
    "tuned_parameters = [{\"n_estimators\":[100,200,300,400,500,600,700,800,900,1000],\n",
    "                   \"max_depth\": [10,20,30,40,50]}]\n",
    "\n",
    "scores = ['accuracy','f1_macro' ,'precision_macro', 'recall_macro', 'roc_auc']\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        estimator= RandomForestClassifier(random_state = 1), param_grid = tuned_parameters, scoring= score,cv = 5, n_jobs = 2\n",
    "    )\n",
    "    clf.fit(transformed_train, train_label)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = holdout_label, clf.predict(transformed_holdout)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
