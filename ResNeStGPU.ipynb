{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Devices: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('Using device:', dev)\n",
    "print(\"GPU Devices:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--base-size BASE_SIZE] [--crop-size CROP_SIZE]\n",
      "                             [--label-smoothing LABEL_SMOOTHING] [--mixup MIXUP] [--rand-aug] [--model MODEL] [--rectify]\n",
      "                             [--rectify-avg] [--pretrained] [--last-gamma] [--dropblock-prob DROPBLOCK_PROB]\n",
      "                             [--final-drop FINAL_DROP] [--batch-size N] [--test-batch-size N] [--epochs N]\n",
      "                             [--start_epoch N] [--workers N] [--lr LR] [--lr-scheduler LR_SCHEDULER]\n",
      "                             [--warmup-epochs WARMUP_EPOCHS] [--momentum M] [--weight-decay M] [--no-bn-wd] [--seed S]\n",
      "                             [--resume RESUME] [--checkname CHECKNAME] [--world-size WORLD_SIZE] [--rank RANK]\n",
      "                             [--dist-url DIST_URL] [--dist-backend DIST_BACKEND] [--eval] [--export EXPORT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ytseng01/.local/share/jupyter/runtime/kernel-e4d158ca-d5e2-4eac-9ac4-01244b78e2ac.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "## Created by: Hang Zhang\n",
    "## Email: zhanghang0704@gmail.com\n",
    "## Copyright (c) 2020\n",
    "##\n",
    "## LICENSE file in the root directory of this source tree\n",
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "from setuptools import setup\n",
    "from torch.utils.cpp_extension import BuildExtension, CppExtension\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from ResNeSt import encoding\n",
    "from ResNeSt.encoding.nn import LabelSmoothing, NLLMultiLabelSmooth\n",
    "from ResNeSt.encoding.utils import (accuracy, AverageMeter, MixUpWrapper, LR_Scheduler, torch_dist_sum)\n",
    "\n",
    "class Options():\n",
    "    def __init__(self):\n",
    "        # data settings\n",
    "        parser = argparse.ArgumentParser(description='Deep Encoding')\n",
    "        parser.add_argument('--dataset', type=str, default='imagenet',\n",
    "                            help='training dataset (default: imagenet)')\n",
    "        parser.add_argument('--base-size', type=int, default=None,\n",
    "                            help='base image size')\n",
    "        parser.add_argument('--crop-size', type=int, default=224,\n",
    "                            help='crop image size')\n",
    "        parser.add_argument('--label-smoothing', type=float, default=0.0,\n",
    "                            help='label-smoothing (default eta: 0.0)')\n",
    "        parser.add_argument('--mixup', type=float, default=0.0,\n",
    "                            help='mixup (default eta: 0.0)')\n",
    "        parser.add_argument('--rand-aug', action='store_true',\n",
    "                            default=False, help='random augment')\n",
    "        # model params\n",
    "        parser.add_argument('--model', type=str, default='densenet',\n",
    "                            help='network model type (default: densenet)')\n",
    "        parser.add_argument('--rectify', action='store_true',\n",
    "                            default=False, help='rectify convolution')\n",
    "        parser.add_argument('--rectify-avg', action='store_true',\n",
    "                            default=False, help='rectify convolution')\n",
    "        parser.add_argument('--pretrained', action='store_true',\n",
    "                            default=False, help='load pretrianed mode')\n",
    "        parser.add_argument('--last-gamma', action='store_true', default=False,\n",
    "                            help='whether to init gamma of the last BN layer in \\\n",
    "                            each bottleneck to 0 (default: False)')\n",
    "        parser.add_argument('--dropblock-prob', type=float, default=0,\n",
    "                            help='DropBlock prob. default is 0.')\n",
    "        parser.add_argument('--final-drop', type=float, default=0,\n",
    "                            help='final dropout prob. default is 0.')\n",
    "        # training params\n",
    "        parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                            help='batch size for training (default: 128)')\n",
    "        parser.add_argument('--test-batch-size', type=int, default=256, metavar='N',\n",
    "                            help='batch size for testing (default: 256)')\n",
    "        parser.add_argument('--epochs', type=int, default=120, metavar='N',\n",
    "                            help='number of epochs to train (default: 600)')\n",
    "        parser.add_argument('--start_epoch', type=int, default=0,\n",
    "                            metavar='N', help='the epoch number to start (default: 1)')\n",
    "        parser.add_argument('--workers', type=int, default=8,\n",
    "                            metavar='N', help='dataloader threads')\n",
    "        # optimizer\n",
    "        parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                            help='learning rate (default: 0.1)')\n",
    "        parser.add_argument('--lr-scheduler', type=str, default='cos',\n",
    "                            help='learning rate scheduler (default: cos)')\n",
    "        parser.add_argument('--warmup-epochs', type=int, default=0,\n",
    "                            help='number of warmup epochs (default: 0)')\n",
    "        parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                            metavar='M', help='SGD momentum (default: 0.9)')\n",
    "        parser.add_argument('--weight-decay', type=float, default=1e-4,\n",
    "                            metavar ='M', help='SGD weight decay (default: 1e-4)')\n",
    "        parser.add_argument('--no-bn-wd', action='store_true',\n",
    "                            default=False, help='no bias decay')\n",
    "        # seed\n",
    "        parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                            help='random seed (default: 1)')\n",
    "        # checking point\n",
    "        parser.add_argument('--resume', type=str, default=None,\n",
    "                            help='put the path to resuming file if needed')\n",
    "        parser.add_argument('--checkname', type=str, default='default',\n",
    "                            help='set the checkpoint name')\n",
    "        # distributed\n",
    "        parser.add_argument('--world-size', default=1, type=int,\n",
    "                            help='number of nodes for distributed training')\n",
    "        parser.add_argument('--rank', default=0, type=int,\n",
    "                            help='node rank for distributed training')\n",
    "        parser.add_argument('--dist-url', default='tcp://localhost:23456', type=str,\n",
    "                            help='url used to set up distributed training')\n",
    "        parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                            help='distributed backend')\n",
    "        # evaluation option\n",
    "        parser.add_argument('--eval', action='store_true', default= False,\n",
    "                            help='evaluating')\n",
    "        parser.add_argument('--export', type=str, default=None,\n",
    "                            help='put the path to resuming file if needed')\n",
    "        self.parser = parser\n",
    "\n",
    "    def parse(self):\n",
    "        args = self.parser.parse_args()\n",
    "        return args\n",
    "\n",
    "# python3 train_dist.py --label-smoothing 0.1 --rectify\n",
    "\n",
    "args = Options().parse()\n",
    "args.model = resnet50\n",
    "args.checkname = resnet50_st\n",
    "args.lr = 0.001\n",
    "args.label_smoothing = 0.1\n",
    "args.rectify = True\n",
    "ngpus_per_node = torch.cuda.device_count()\n",
    "args.world_size = ngpus_per_node * args.world_size\n",
    "args.lr = args.lr * args.world_size\n",
    "print(\"Wrapping\")\n",
    "mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "print(\"Wrapped\")\n",
    "\n",
    "# global variable\n",
    "best_pred = 0.0\n",
    "acclist_train = []\n",
    "acclist_val = []\n",
    "\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    print(\"Worker CPU\", gpu)\n",
    "    args.gpu = gpu\n",
    "    args.rank = args.rank * ngpus_per_node + gpu\n",
    "    print('rank: {} / {}'.format(args.rank, args.world_size))\n",
    "    dist.init_process_group(backend=args.dist_backend,\n",
    "                            init_method=args.dist_url,\n",
    "                            world_size=args.world_size,\n",
    "                            rank=args.rank)\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    # init the args\n",
    "    global best_pred, acclist_train, acclist_val\n",
    "\n",
    "    if args.gpu == 0:\n",
    "        print(args)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    # init dataloader\n",
    "    transform_train, transform_val = encoding.transforms.get_transform(\n",
    "            args.dataset, args.base_size, args.crop_size, args.rand_aug)\n",
    "    trainset = encoding.datasets.get_dataset(args.dataset, root=os.path.expanduser('~/MScProject/Colour_MFCC'),\n",
    "                                             transform=transform_train, train=True, download=True)\n",
    "    valset = encoding.datasets.get_dataset(args.dataset, root=os.path.expanduser('~/encoding/data'),\n",
    "                                           transform=transform_val, train=False, download=True)\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(valset, shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=args.test_batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True,\n",
    "        sampler=val_sampler)\n",
    "\n",
    "    # init the model\n",
    "    model_kwargs = {}\n",
    "    if args.pretrained:\n",
    "        model_kwargs['pretrained'] = True\n",
    "\n",
    "    if args.final_drop > 0.0:\n",
    "        model_kwargs['final_drop'] = args.final_drop\n",
    "\n",
    "    if args.dropblock_prob > 0.0:\n",
    "        model_kwargs['dropblock_prob'] = args.dropblock_prob\n",
    "\n",
    "    if args.last_gamma:\n",
    "        model_kwargs['last_gamma'] = True\n",
    "\n",
    "    if args.rectify:\n",
    "        model_kwargs['rectified_conv'] = True\n",
    "        model_kwargs['rectify_avg'] = args.rectify_avg\n",
    "\n",
    "    model = encoding.models.get_model(args.model, **model_kwargs)\n",
    "\n",
    "    if args.dropblock_prob > 0.0:\n",
    "        from functools import partial\n",
    "        from encoding.nn import reset_dropblock\n",
    "        nr_iters = (args.epochs - args.warmup_epochs) * len(train_loader)\n",
    "        apply_drop_prob = partial(reset_dropblock, args.warmup_epochs*len(train_loader),\n",
    "                                  nr_iters, 0.0, args.dropblock_prob)\n",
    "        model.apply(apply_drop_prob)\n",
    "\n",
    "    if args.gpu == 0:\n",
    "        print(model)\n",
    "\n",
    "    if args.mixup > 0:\n",
    "        train_loader = MixUpWrapper(args.mixup, 1000, train_loader, args.gpu)\n",
    "        criterion = NLLMultiLabelSmooth(args.label_smoothing)\n",
    "    elif args.label_smoothing > 0.0:\n",
    "        criterion = LabelSmoothing(args.label_smoothing)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.cuda(args.gpu)\n",
    "    criterion.cuda(args.gpu)\n",
    "    model = DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "\n",
    "    # criterion and optimizer\n",
    "    if args.no_bn_wd:\n",
    "        parameters = model.named_parameters()\n",
    "        param_dict = {}\n",
    "        for k, v in parameters:\n",
    "            param_dict[k] = v\n",
    "        bn_params = [v for n, v in param_dict.items() if ('bn' in n or 'bias' in n)]\n",
    "        rest_params = [v for n, v in param_dict.items() if not ('bn' in n or 'bias' in n)]\n",
    "        if args.gpu == 0:\n",
    "            print(\" Weight decay NOT applied to BN parameters \")\n",
    "            print(f'len(parameters): {len(list(model.parameters()))} = {len(bn_params)} + {len(rest_params)}')\n",
    "        optimizer = torch.optim.SGD([{'params': bn_params, 'weight_decay': 0 },\n",
    "                                     {'params': rest_params, 'weight_decay': args.weight_decay}],\n",
    "                                    lr=args.lr,\n",
    "                                    momentum=args.momentum,\n",
    "                                    weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                    lr=args.lr,\n",
    "                                    momentum=args.momentum,\n",
    "                                    weight_decay=args.weight_decay)\n",
    "    # check point\n",
    "    if args.resume is not None:\n",
    "        if os.path.isfile(args.resume):\n",
    "            if args.gpu == 0:\n",
    "                print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch'] + 1 if args.start_epoch == 0 else args.start_epoch\n",
    "            best_pred = checkpoint['best_pred']\n",
    "            acclist_train = checkpoint['acclist_train']\n",
    "            acclist_val = checkpoint['acclist_val']\n",
    "            model.module.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            if args.gpu == 0:\n",
    "                print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            raise RuntimeError (\"=> no resume checkpoint found at '{}'\".\\\n",
    "                format(args.resume))\n",
    "    scheduler = LR_Scheduler(args.lr_scheduler,\n",
    "                             base_lr=args.lr,\n",
    "                             num_epochs=args.epochs,\n",
    "                             iters_per_epoch=len(train_loader),\n",
    "                             warmup_epochs=args.warmup_epochs)\n",
    "    def train(epoch):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        global best_pred, acclist_train\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            scheduler(optimizer, batch_idx, epoch, best_pred)\n",
    "            if not args.mixup:\n",
    "                data, target = data.cuda(args.gpu), target.cuda(args.gpu)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if not args.mixup:\n",
    "                acc1 = accuracy(output, target, topk=(1,))\n",
    "                top1.update(acc1[0], data.size(0))\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            if batch_idx % 100 == 0 and args.gpu == 0:\n",
    "                if args.mixup:\n",
    "                    print('Batch: %d| Loss: %.3f'%(batch_idx, losses.avg))\n",
    "                else:\n",
    "                    print('Batch: %d| Loss: %.3f | Top1: %.3f'%(batch_idx, losses.avg, top1.avg))\n",
    "\n",
    "        acclist_train += [top1.avg]\n",
    "\n",
    "    def validate(epoch):\n",
    "        model.eval()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "        global best_pred, acclist_train, acclist_val\n",
    "        is_best = False\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.cuda(args.gpu), target.cuda(args.gpu)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "                top1.update(acc1[0], data.size(0))\n",
    "                top5.update(acc5[0], data.size(0))\n",
    "\n",
    "        # sum all\n",
    "        sum1, cnt1, sum5, cnt5 = torch_dist_sum(args.gpu, top1.sum, top1.count, top5.sum, top5.count)\n",
    "\n",
    "        if args.eval:\n",
    "            if args.gpu == 0:\n",
    "                top1_acc = sum(sum1) / sum(cnt1)\n",
    "                top5_acc = sum(sum5) / sum(cnt5)\n",
    "                print('Validation: Top1: %.3f | Top5: %.3f'%(top1_acc, top5_acc))\n",
    "            return\n",
    "\n",
    "        if args.gpu == 0:\n",
    "            top1_acc = sum(sum1) / sum(cnt1)\n",
    "            top5_acc = sum(sum5) / sum(cnt5)\n",
    "            print('Validation: Top1: %.3f | Top5: %.3f'%(top1_acc, top5_acc))\n",
    "\n",
    "            # save checkpoint\n",
    "            acclist_val += [top1_acc]\n",
    "            if top1_acc > best_pred:\n",
    "                best_pred = top1_acc\n",
    "                is_best = True\n",
    "            encoding.utils.save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.module.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_pred': best_pred,\n",
    "                'acclist_train':acclist_train,\n",
    "                'acclist_val':acclist_val,\n",
    "                }, args=args, is_best=is_best)\n",
    "\n",
    "    if args.export:\n",
    "        if args.gpu == 0:\n",
    "            torch.save(model.module.state_dict(), args.export + '.pth')\n",
    "        return\n",
    "\n",
    "    if args.eval:\n",
    "        validate(args.start_epoch)\n",
    "        return\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        tic = time.time()\n",
    "        train(epoch)\n",
    "        if epoch % 10 == 0:# or epoch == args.epochs-1:\n",
    "            validate(epoch)\n",
    "        elapsed = time.time() - tic\n",
    "        if args.gpu == 0:\n",
    "            print(f'Epoch: {epoch}, Time cost: {elapsed}')\n",
    "\n",
    "    if args.gpu == 0:\n",
    "        encoding.utils.save_checkpoint({\n",
    "            'epoch': args.epochs-1,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_pred': best_pred,\n",
    "            'acclist_train':acclist_train,\n",
    "            'acclist_val':acclist_val,\n",
    "            }, args=args, is_best=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
